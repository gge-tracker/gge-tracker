##########################################################################################
#                                     __                        __                       #
#      ____   ____   ____           _/  |_____________    ____ |  | __ ___________       #
#     / ___\ / ___\_/ __ \   ______ \   __\_  __ \__  \ _/ ___\|  |/ // __ \_  __ \      #
#    / /_/  > /_/  >  ___/  /_____/  |  |  |  | \// __ \\  \___|    <\  ___/|  | \/      #
#    \___  /\___  / \___  >          |__|  |__|  (____  /\___  >__|_ \\___  >__|         #
#   /_____//_____/      \/                            \/     \/     \/    \/             #
#                                                                                        #
#                     This file is part of the gge-tracker project.                      #
#        Copyrights (c) 2025 - gge-tracker.com & gge-tracker contributors                #
#                                                                                        #
# This docker-compose file defines common services used across different environments.   #
# It is intended to be extended by other docker-compose files (e.g., dev, production).   #
#                                                                                        #
##########################################################################################
name: gge-tracker

services:

  frontend-angular-node:
    build:
      context: ./../gge-tracker-frontend
      dockerfile: Dockerfile.serve
    container_name: frontend-container-node
    volumes:
      - ./../gge-tracker-frontend:/app
      - /app/node_modules
    networks:
      - backend
    restart: always

  frontend-angular-nginx:
    build:
      context: ./../gge-tracker-frontend
      dockerfile: Dockerfile
    image: frontend-angular:latest
    container_name: frontend-container-nginx
    restart: always
    volumes:
      - ./../gge-tracker-frontend/dist/gge-tracker-frontend/browser/sitemaps:/usr/share/nginx/html/gge-tracker-frontend/browser/sitemaps:rw

  postgres:
    image: postgres:18.0
    container_name: postgres-container
    environment:
      POSTGRES_DB: ${SQL_DATABASE}
      POSTGRES_USER: ${SQL_USER}
      POSTGRES_PASSWORD: ${SQL_PASSWORD}
    volumes:
      - pg_data:/var/lib/postgresql/data
    networks:
      - backend
    restart: always
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${SQL_USER} -d ${SQL_DATABASE}"]
      interval: 5s
      timeout: 5s
      retries: 5

  mariadb:
    image: mariadb:12.0.2
    container_name: mariadb-container
    cpu_quota: 80000
    cpu_period: 100000
    environment:
      MYSQL_ROOT_PASSWORD: ${SQL_ROOT_PASSWORD}
      MYSQL_DATABASE: ${SQL_DATABASE}
      MYSQL_USER: ${SQL_USER}
      MYSQL_PASSWORD: ${SQL_PASSWORD}
    volumes:
      - db_data:/var/lib/mysql
      - ./../database/conf/mariadb.cnf:/etc/mysql/conf.d/my.cnf:ro
    networks:
      - backend
    restart: always
    healthcheck:
      test: ["CMD", "healthcheck.sh", "--connect", "--innodb_initialized"]
      start_period: 5s
      interval: 5s
      timeout: 5s
      retries: 3

  clickhouse:
    image: clickhouse/clickhouse-server:25.4.2.31
    container_name: clickhouse
    environment:
      - CLICKHOUSE_USER=${CLICKHOUSE_USER}
      - CLICKHOUSE_PASSWORD=${CLICKHOUSE_PASSWORD}
      - CLICKHOUSE_S3_ENDPOINT=${CLICKHOUSE_S3_ENDPOINT}
      - CLICKHOUSE_S3_ACCESS_KEY=${CLICKHOUSE_S3_ACCESS_KEY}
      - CLICKHOUSE_S3_SECRET_KEY=${CLICKHOUSE_S3_SECRET_KEY}
      - CLICKHOUSE_STORAGE=${CLICKHOUSE_STORAGE}
    volumes:
      - clickhouse_data:/var/lib/clickhouse
      - ./../database/conf/clickhouse_${CLICKHOUSE_STORAGE}.xml:/etc/clickhouse-server/config.d/s3.xml:ro
    healthcheck:
      test: ["CMD-SHELL", "clickhouse-client --user=${CLICKHOUSE_USER} --password=${CLICKHOUSE_PASSWORD} --query='SELECT 1'"]
      interval: 10s
      timeout: 5s
      retries: 5
    ulimits:
      nofile:
        soft: 262144
        hard: 262144
    restart: always
    networks:
      - backend

  clickhouse-webui:
    image: spoonest/clickhouse-tabix-web-client@sha256:fd2b754a5d379e8bb9b0019e1c757ae02ab54c304f590ae2d0e856fbc05feae2
    cpu_quota: 20000
    cpu_period: 100000
    mem_limit: 200m
    container_name: clickhouse-ui
    environment:
      - CLICKHOUSE_SERVER=http://clickhouse:8123
    depends_on:
      - clickhouse
    networks:
      - backend

  backend-express-rest-api:
    image: backend-express-rest-api:latest
    container_name: backend-container
    working_dir: /app
    networks:
      - backend
    restart: always
    environment:
      - MYSQL_HOST=${MARIADB_HOST}
      - MYSQL_DATABASE=${SQL_DATABASE}
      - MYSQL_USER=${SQL_USER}
      - MYSQL_PASSWORD=${SQL_PASSWORD}
      - POSTGRES_HOST=${PG_HOST}
      - POSTGRES_DATABASE=${SQL_DATABASE}
      - POSTGRES_USER=${SQL_USER}
      - POSTGRES_PASSWORD=${SQL_PASSWORD}
      - CLICKHOUSE_HOST=${CLICKHOUSE_HOST}
      - CLICKHOUSE_USER=${CLICKHOUSE_USER}
      - CLICKHOUSE_PASSWORD=${CLICKHOUSE_PASSWORD}
      - LOKI_HOST=loki
      - LOKI_PORT=3100
      - REDIS_URL=redis://redis-server:6379
      - INTERNAL_SECRET=${INTERNAL_SECRET}
      - GGE_API_URL=${GGE_API_URL}:${GGE_API_PORT}
    depends_on:
      mariadb:
        condition: service_healthy
      redis-server:
        condition: service_healthy
      postgres:
        condition: service_healthy

  redis-server:
    image: redis:8.2
    container_name: redis-container
    command: redis-server --maxmemory 512mb --maxmemory-policy allkeys-lru --lazyfree-lazy-eviction yes --lazyfree-lazy-expire yes --lazyfree-lazy-server-del yes --maxclients 1000
    networks:
      - backend
    healthcheck:
      test: [ "CMD", "redis-cli", "--raw", "incr", "ping" ]
      start_period: 5s
      interval: 5s
      timeout: 5s

  empire-api:
    build:
      context: ./../empire-api
      dockerfile: Dockerfile
    container_name: empire-api-container
    environment:
      NODE_ENV: production
    networks:
      - backend
    restart: always

  empire-api-realtime:
    build:
      context: ./../empire-api
      dockerfile: Dockerfile
      args:
        HAS_GBL: "true"
    container_name: empire-api-container-realtime
    environment:
      NODE_ENV: production
      HAS_GBL: "true"
    networks:
      - backend
    restart: always

  sitemap-generator:
    build:
      context: ./../sitemap-generator
      dockerfile: Dockerfile
    container_name: sitemap-generator
    environment:
      MYSQL_USER: "${SQL_USER}"
      MYSQL_PASSWORD: "${SQL_PASSWORD}"
    volumes:
      - ./../gge-tracker-frontend/dist/gge-tracker-frontend/browser/sitemaps:/usr/share/nginx/html/gge-tracker-frontend/browser/sitemaps
    networks:
      - backend
    restart: "no"

  grafana:
    image: grafana/grafana:12.2
    mem_limit: 400m
    cpu_quota: 40000
    cpu_period: 100000
    container_name: grafana
    volumes:
      - ./../monitoring/grafana/provisioning:/etc/grafana/provisioning
      - ./../monitoring/grafana/dashboards:/var/lib/grafana/dashboards
    depends_on:
      - prometheus
      - loki
    networks:
      - backend
    environment:
      - GF_SECURITY_ADMIN_USER=${GF_USERNAME}
      - GF_SECURITY_ADMIN_PASSWORD=${GF_PASSWORD}
      - GF_PATHS_PROVISIONING=/etc/grafana/provisioning
      - GF_LOG_LEVEL=${GF_LOG_LEVEL}
    restart: "no"

  prometheus:
    image: prom/prometheus:v3.6.0
    mem_limit: 300m
    cpu_quota: 30000
    cpu_period: 100000
    container_name: prometheus
    volumes:
      - ./../monitoring/prometheus.yml:/etc/prometheus/prometheus.yml
    networks:
      - backend
    restart: always
    command:
      - "--log.level=${PROMETHEUS_LOG_LEVEL:-warn}"
      - "--config.file=/etc/prometheus/prometheus.yml"

  node-exporter:
    image: prom/node-exporter:v1.9.1
    mem_limit: 100m
    cpu_quota: 10000
    cpu_period: 100000
    container_name: node-exporter
    networks:
      - backend
    restart: always

  promtail:
    image: grafana/promtail:2.9.2
    mem_limit: 200m
    cpu_quota: 30000
    cpu_period: 100000
    container_name: promtail
    volumes:
      - /var/log:/var/log
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
      - /etc/machine-id:/etc/machine-id
      - ./../monitoring/promtail-config.yml:/etc/promtail/config.yml
    command: -config.file=/etc/promtail/config.yml
    networks:
      - backend
    restart: always

  cadvisor:
    image: gcr.io/cadvisor/cadvisor:v0.49.1
    container_name: cadvisor
    command:
      - "--v=0"
    volumes:
      - /:/rootfs:ro
      - /var/run:/var/run:ro
      - /sys:/sys:ro
      - /var/lib/docker/:/var/lib/docker:ro
    networks:
      - backend
    restart: unless-stopped

  database-migrate:
    container_name: database-migrate
    hostname: database-migrate
    image: database-migrate:latest
    build:
      context: ./../database
      dockerfile: Dockerfile
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - /etc/localtime:/etc/localtime:ro
    working_dir: /scripts
    command: ["bash", "./db_migrate.sh"]
    environment:
      - SQL_USER=${SQL_USER}
      - SQL_PASSWORD=${SQL_PASSWORD}
      - SQL_ROOT_PASSWORD=${SQL_ROOT_PASSWORD}
      - SQL_DATABASE=${SQL_DATABASE}
      - PG_HOST=${PG_HOST}
      - MARIADB_HOST=${MARIADB_HOST}
      - CLICKHOUSE_HOST=${CLICKHOUSE_HOST}
      - CLICKHOUSE_USER=${CLICKHOUSE_USER}
      - CLICKHOUSE_PASSWORD=${CLICKHOUSE_PASSWORD}
    depends_on:
      mariadb:
        condition: service_healthy
      postgres:
        condition: service_healthy
      clickhouse:
        condition: service_healthy
    networks:
      - backend
    restart: "no"

  loki:
    image: grafana/loki:2.9.2
    mem_limit: 250m
    cpu_quota: 30000
    cpu_period: 100000
    container_name: loki
    volumes:
      - ./../monitoring/loki-config.yml:/etc/loki/local-config.yaml
    command: -config.file=/etc/loki/local-config.yaml
    networks:
      - backend
    restart: always
